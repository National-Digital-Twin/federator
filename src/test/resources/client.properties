kafka.sender.defaultKeySerializerClass=org.apache.kafka.common.serialization.BytesSerializer
kafka.sender.defaultValueSerializerClass=org.apache.kafka.common.serialization.BytesSerializer
kafka.bootstrapServers=kafka-target:19092

###
### The following are the controls used when read from topics used by the client and the server
###
## Default retries.max_attempts is 200
retries.max_attempts=1
## Default retries.initial_backoff is 500 (ms)
retries.initial_backoff=1
## Default retries.max_backoff is 60000 (ms)
retries.max_backoff=2
## Default retries.forever is true (retry forever)
## Back off time doubles every iteration up to the max_backoff time. After max attempts it exits
## if the reties.forever is set to false.
#retries.forever=

## kafka.topic.prefix default is empty string
kafka.topic.prefix=federated
kafka.consumerGroup=ndtp.dbt.gov.uk
## Default redis.host is localhost
redis.host=redis
## Default redis.port is 6379
redis.port=6379
## Default redis.tls.enabled empty value "" = false, missing property entry = true
redis.tls.enabled=false
# If redis authentication is enabled then set the username and password here. If only a password is required then keep the username as an empty string.
redis.username=
redis.password=
# For access token cached in Redis set this property to an AES key (Base64 encoded) for encryption/decryption purposes.
redis.aes.key=
connections.configuration=src/test/resources/connection-configuration.json
common.configuration=src/test/resources/common-configuration.properties
